services:
  # Main MiaAI application
  miaai:
    build: .
    container_name: miaai-app
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - ./app:/app/app
      - ./data:/app/data      # Persistent data directory
      - ./documents:/app/documents
      - ./output_documents:/app/output_documents
      - ./config:/app/config  # Configuration files
    environment:
      - FLASK_APP=app
      - FLASK_ENV=development
      - FLASK_DEBUG=1
      - DATABASE_PATH=/app/data/memories.db
      
      # LLM Provider Configuration
      - LLM_PROVIDER=ollama
      - OLLAMA_HOST=host.docker.internal
      - OLLAMA_PORT=11434
      
      # OpenAI Configuration (optional)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-3.5-turbo}
      
      # Anthropic Configuration (optional)
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-instant-1}
    networks:
      - miaai-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Optional Ngrok tunnel for remote access
  # To use this, add NGROK_AUTH_TOKEN to your .env file and
  # run with: docker-compose --profile with-ngrok up -d
  ngrok:
    image: ngrok/ngrok:alpine
    container_name: ngrok-tunnel
    restart: unless-stopped
    depends_on:
      - miaai
    ports:
      - "4040:4040"
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTH_TOKEN:-}
    command: http miaai:8080
    networks:
      - miaai-network
    profiles:
      - with-ngrok

volumes:
  ollama_data:
    name: miaai-ollama-data

networks:
  miaai-network:
    driver: bridge